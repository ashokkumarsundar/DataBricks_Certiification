{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\nspark=SparkSession.builder.getOrCreate()\n\nsc=spark.sparkContext\n\n\na=sc.parallelize([1,2,3,4])\n'''b1=sc.textFile(\"/FileStore/tables/people.txt\")\nc=b1.map(lambda x:x.split(\",\")).filter(lambda (x,y):int(y)>20)\nc.collect()\n'''\n\na.map(lambda x:x+1).collect()\na.getNumPartitions()\n\na.repartition(4).collect()\n\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">1</span><span class=\"ansired\">]: </span>[2, 1, 3, 4]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["b1=sc.textFile(\"/FileStore/tables/people.txt\")\n\nb1.collect()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">47</span><span class=\"ansired\">]: </span>[u&apos;Michael, 29&apos;, u&apos;Andy, 30&apos;, u&apos;Justin, 19&apos;]\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["c1=sc.textFile(\"/FileStore/tables/Dep1.txt\")\nc1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">50</span><span class=\"ansired\">]: </span>[u&apos;29,Dep1&apos;, u&apos;30,Dep2&apos;, u&apos;19,Dep3&apos;]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["empKV=b1.map(lambda x: x.split(\",\")).map(lambda a: (int(a[1]),a))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["depKV=c1.map(lambda x: x.split(\",\")).map(lambda a: (int(a[0]),a))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">58</span><span class=\"ansired\">]: </span>[(29, [u&apos;29&apos;, u&apos;Dep1&apos;]), (30, [u&apos;30&apos;, u&apos;Dep2&apos;]), (19, [u&apos;19&apos;, u&apos;Dep3&apos;])]\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["depKV.cache()\nfinalDF=empKV.join(depKV).join(depKV)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["empKV.join(depKV).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">67</span><span class=\"ansired\">]: </span>\n[(29, ([u&apos;Michael&apos;, u&apos; 29&apos;], [u&apos;29&apos;, u&apos;Dep1&apos;])),\n (30, ([u&apos;Andy&apos;, u&apos; 30&apos;], [u&apos;30&apos;, u&apos;Dep2&apos;])),\n (19, ([u&apos;Justin&apos;, u&apos; 19&apos;], [u&apos;19&apos;, u&apos;Dep3&apos;]))]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["finalDF.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">64</span><span class=\"ansired\">]: </span>\n[(30, (([u&apos;Andy&apos;, u&apos; 30&apos;], [u&apos;30&apos;, u&apos;Dep2&apos;]), [u&apos;30&apos;, u&apos;Dep2&apos;])),\n (19, (([u&apos;Justin&apos;, u&apos; 19&apos;], [u&apos;19&apos;, u&apos;Dep3&apos;]), [u&apos;19&apos;, u&apos;Dep3&apos;])),\n (29, (([u&apos;Michael&apos;, u&apos; 29&apos;], [u&apos;29&apos;, u&apos;Dep1&apos;]), [u&apos;29&apos;, u&apos;Dep1&apos;]))]\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["empKV.join(depKV).toDebugString()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">66</span><span class=\"ansired\">]: </span>&apos;(4) PythonRDD[232] at RDD at PythonRDD.scala:55 []\\n |  MapPartitionsRDD[231] at mapPartitions at PythonRDD.scala:165 []\\n |  ShuffledRDD[230] at partitionBy at NativeMethodAccessorImpl.java:0 []\\n +-(4) PairwiseRDD[229] at join at &lt;command-496538373508813&gt;:1 []\\n    |  PythonRDD[228] at join at &lt;command-496538373508813&gt;:1 []\\n    |  UnionRDD[227] at union at NativeMethodAccessorImpl.java:0 []\\n    |  PythonRDD[225] at RDD at PythonRDD.scala:55 []\\n    |  /FileStore/tables/people.txt MapPartitionsRDD[115] at textFile at &lt;unknown&gt;:0 []\\n    |  /FileStore/tables/people.txt HadoopRDD[114] at textFile at &lt;unknown&gt;:0 []\\n    |  PythonRDD[226] at RDD at PythonRDD.scala:55 []\\n    |  PythonRDD[126] at collect at &lt;command-496538373508799&gt;:2 []\\n    |      CachedPartitions: 2; MemorySize: 187.0 B; ExternalBlockStoreSize: 0.0 B; DiskSize: 0.0 B\\n    |  /FileStore/tables/Dep1.txt MapPartitionsRDD[119] at textFile at &lt;unknown&gt;:0 []\\n    |  /FileStore/tables/Dep1.txt HadoopRDD[118] at textFile at &lt;unknown&gt;:0 []&apos;\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["wcRDD=sc.textFile(\"/FileStore/tables/wc.txt\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["a=wcRDD.map(lambda x: x.split(\" \"))\na.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">70</span><span class=\"ansired\">]: </span>\n[[u&apos;RDDs&apos;,\n  u&apos;support&apos;,\n  u&apos;two&apos;,\n  u&apos;types&apos;,\n  u&apos;of&apos;,\n  u&apos;operations:&apos;,\n  u&apos;transformations,&apos;,\n  u&apos;which&apos;,\n  u&apos;create&apos;,\n  u&apos;a&apos;,\n  u&apos;new&apos;,\n  u&apos;dataset&apos;,\n  u&apos;from&apos;,\n  u&apos;an&apos;,\n  u&apos;existing&apos;,\n  u&apos;one,&apos;,\n  u&apos;and&apos;,\n  u&apos;actions,&apos;,\n  u&apos;which&apos;,\n  u&apos;return&apos;,\n  u&apos;a&apos;,\n  u&apos;value&apos;,\n  u&apos;to&apos;,\n  u&apos;the&apos;,\n  u&apos;driver&apos;,\n  u&apos;program&apos;,\n  u&apos;after&apos;,\n  u&apos;running&apos;,\n  u&apos;a&apos;,\n  u&apos;computation&apos;,\n  u&apos;on&apos;,\n  u&apos;the&apos;,\n  u&apos;dataset.&apos;,\n  u&apos;For&apos;,\n  u&apos;example,&apos;,\n  u&apos;map&apos;,\n  u&apos;is&apos;,\n  u&apos;a&apos;,\n  u&apos;transformation&apos;,\n  u&apos;that&apos;,\n  u&apos;passes&apos;,\n  u&apos;each&apos;,\n  u&apos;dataset&apos;,\n  u&apos;element&apos;,\n  u&apos;through&apos;,\n  u&apos;a&apos;,\n  u&apos;function&apos;,\n  u&apos;and&apos;,\n  u&apos;returns&apos;,\n  u&apos;a&apos;,\n  u&apos;new&apos;,\n  u&apos;RDD&apos;,\n  u&apos;representing&apos;,\n  u&apos;the&apos;,\n  u&apos;results.&apos;,\n  u&apos;On&apos;,\n  u&apos;the&apos;,\n  u&apos;other&apos;,\n  u&apos;hand,&apos;,\n  u&apos;reduce&apos;,\n  u&apos;is&apos;,\n  u&apos;an&apos;,\n  u&apos;action&apos;,\n  u&apos;that&apos;,\n  u&apos;aggregates&apos;,\n  u&apos;all&apos;,\n  u&apos;the&apos;,\n  u&apos;elements&apos;,\n  u&apos;of&apos;,\n  u&apos;the&apos;,\n  u&apos;RDD&apos;,\n  u&apos;using&apos;,\n  u&apos;some&apos;,\n  u&apos;function&apos;,\n  u&apos;and&apos;,\n  u&apos;returns&apos;,\n  u&apos;the&apos;,\n  u&apos;final&apos;,\n  u&apos;result&apos;,\n  u&apos;to&apos;,\n  u&apos;the&apos;,\n  u&apos;driver&apos;,\n  u&apos;program&apos;,\n  u&apos;(although&apos;,\n  u&apos;there&apos;,\n  u&apos;is&apos;,\n  u&apos;also&apos;,\n  u&apos;a&apos;,\n  u&apos;parallel&apos;,\n  u&apos;reduceByKey&apos;,\n  u&apos;that&apos;,\n  u&apos;returns&apos;,\n  u&apos;a&apos;,\n  u&apos;distributed&apos;,\n  u&apos;dataset).&apos;],\n [u&apos;&apos;],\n [u&apos;All&apos;,\n  u&apos;transformations&apos;,\n  u&apos;in&apos;,\n  u&apos;Spark&apos;,\n  u&apos;are&apos;,\n  u&apos;lazy,&apos;,\n  u&apos;in&apos;,\n  u&apos;that&apos;,\n  u&apos;they&apos;,\n  u&apos;do&apos;,\n  u&apos;not&apos;,\n  u&apos;compute&apos;,\n  u&apos;their&apos;,\n  u&apos;results&apos;,\n  u&apos;right&apos;,\n  u&apos;away.&apos;,\n  u&apos;Instead,&apos;,\n  u&apos;they&apos;,\n  u&apos;just&apos;,\n  u&apos;remember&apos;,\n  u&apos;the&apos;,\n  u&apos;transformations&apos;,\n  u&apos;applied&apos;,\n  u&apos;to&apos;,\n  u&apos;some&apos;,\n  u&apos;base&apos;,\n  u&apos;dataset&apos;,\n  u&apos;(e.g.&apos;,\n  u&apos;a&apos;,\n  u&apos;file).&apos;,\n  u&apos;The&apos;,\n  u&apos;transformations&apos;,\n  u&apos;are&apos;,\n  u&apos;only&apos;,\n  u&apos;computed&apos;,\n  u&apos;when&apos;,\n  u&apos;an&apos;,\n  u&apos;action&apos;,\n  u&apos;requires&apos;,\n  u&apos;a&apos;,\n  u&apos;result&apos;,\n  u&apos;to&apos;,\n  u&apos;be&apos;,\n  u&apos;returned&apos;,\n  u&apos;to&apos;,\n  u&apos;the&apos;,\n  u&apos;driver&apos;,\n  u&apos;program.&apos;,\n  u&apos;This&apos;,\n  u&apos;design&apos;,\n  u&apos;enables&apos;,\n  u&apos;Spark&apos;,\n  u&apos;to&apos;,\n  u&apos;run&apos;,\n  u&apos;more&apos;,\n  u&apos;efficiently.&apos;,\n  u&apos;For&apos;,\n  u&apos;example,&apos;,\n  u&apos;we&apos;,\n  u&apos;can&apos;,\n  u&apos;realize&apos;,\n  u&apos;that&apos;,\n  u&apos;a&apos;,\n  u&apos;dataset&apos;,\n  u&apos;created&apos;,\n  u&apos;through&apos;,\n  u&apos;map&apos;,\n  u&apos;will&apos;,\n  u&apos;be&apos;,\n  u&apos;used&apos;,\n  u&apos;in&apos;,\n  u&apos;a&apos;,\n  u&apos;reduce&apos;,\n  u&apos;and&apos;,\n  u&apos;return&apos;,\n  u&apos;only&apos;,\n  u&apos;the&apos;,\n  u&apos;result&apos;,\n  u&apos;of&apos;,\n  u&apos;the&apos;,\n  u&apos;reduce&apos;,\n  u&apos;to&apos;,\n  u&apos;the&apos;,\n  u&apos;driver,&apos;,\n  u&apos;rather&apos;,\n  u&apos;than&apos;,\n  u&apos;the&apos;,\n  u&apos;larger&apos;,\n  u&apos;mapped&apos;,\n  u&apos;dataset.&apos;],\n [u&apos;&apos;],\n [u&apos;By&apos;,\n  u&apos;default,&apos;,\n  u&apos;each&apos;,\n  u&apos;transformed&apos;,\n  u&apos;RDD&apos;,\n  u&apos;may&apos;,\n  u&apos;be&apos;,\n  u&apos;recomputed&apos;,\n  u&apos;each&apos;,\n  u&apos;time&apos;,\n  u&apos;you&apos;,\n  u&apos;run&apos;,\n  u&apos;an&apos;,\n  u&apos;action&apos;,\n  u&apos;on&apos;,\n  u&apos;it.&apos;,\n  u&apos;However,&apos;,\n  u&apos;you&apos;,\n  u&apos;may&apos;,\n  u&apos;also&apos;,\n  u&apos;persist&apos;,\n  u&apos;an&apos;,\n  u&apos;RDD&apos;,\n  u&apos;in&apos;,\n  u&apos;memory&apos;,\n  u&apos;using&apos;,\n  u&apos;the&apos;,\n  u&apos;persist&apos;,\n  u&apos;(or&apos;,\n  u&apos;cache)&apos;,\n  u&apos;method,&apos;,\n  u&apos;in&apos;,\n  u&apos;which&apos;,\n  u&apos;case&apos;,\n  u&apos;Spark&apos;,\n  u&apos;will&apos;,\n  u&apos;keep&apos;,\n  u&apos;the&apos;,\n  u&apos;elements&apos;,\n  u&apos;around&apos;,\n  u&apos;on&apos;,\n  u&apos;the&apos;,\n  u&apos;cluster&apos;,\n  u&apos;for&apos;,\n  u&apos;much&apos;,\n  u&apos;faster&apos;,\n  u&apos;access&apos;,\n  u&apos;the&apos;,\n  u&apos;next&apos;,\n  u&apos;time&apos;,\n  u&apos;you&apos;,\n  u&apos;query&apos;,\n  u&apos;it.&apos;,\n  u&apos;There&apos;,\n  u&apos;is&apos;,\n  u&apos;also&apos;,\n  u&apos;support&apos;,\n  u&apos;for&apos;,\n  u&apos;persisting&apos;,\n  u&apos;RDDs&apos;,\n  u&apos;on&apos;,\n  u&apos;disk,&apos;,\n  u&apos;or&apos;,\n  u&apos;replicated&apos;,\n  u&apos;across&apos;,\n  u&apos;multiple&apos;,\n  u&apos;nodes.&apos;]]\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["a1=wcRDD.flatMap(lambda x: x.split(\" \"))\na1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">71</span><span class=\"ansired\">]: </span>\n[u&apos;RDDs&apos;,\n u&apos;support&apos;,\n u&apos;two&apos;,\n u&apos;types&apos;,\n u&apos;of&apos;,\n u&apos;operations:&apos;,\n u&apos;transformations,&apos;,\n u&apos;which&apos;,\n u&apos;create&apos;,\n u&apos;a&apos;,\n u&apos;new&apos;,\n u&apos;dataset&apos;,\n u&apos;from&apos;,\n u&apos;an&apos;,\n u&apos;existing&apos;,\n u&apos;one,&apos;,\n u&apos;and&apos;,\n u&apos;actions,&apos;,\n u&apos;which&apos;,\n u&apos;return&apos;,\n u&apos;a&apos;,\n u&apos;value&apos;,\n u&apos;to&apos;,\n u&apos;the&apos;,\n u&apos;driver&apos;,\n u&apos;program&apos;,\n u&apos;after&apos;,\n u&apos;running&apos;,\n u&apos;a&apos;,\n u&apos;computation&apos;,\n u&apos;on&apos;,\n u&apos;the&apos;,\n u&apos;dataset.&apos;,\n u&apos;For&apos;,\n u&apos;example,&apos;,\n u&apos;map&apos;,\n u&apos;is&apos;,\n u&apos;a&apos;,\n u&apos;transformation&apos;,\n u&apos;that&apos;,\n u&apos;passes&apos;,\n u&apos;each&apos;,\n u&apos;dataset&apos;,\n u&apos;element&apos;,\n u&apos;through&apos;,\n u&apos;a&apos;,\n u&apos;function&apos;,\n u&apos;and&apos;,\n u&apos;returns&apos;,\n u&apos;a&apos;,\n u&apos;new&apos;,\n u&apos;RDD&apos;,\n u&apos;representing&apos;,\n u&apos;the&apos;,\n u&apos;results.&apos;,\n u&apos;On&apos;,\n u&apos;the&apos;,\n u&apos;other&apos;,\n u&apos;hand,&apos;,\n u&apos;reduce&apos;,\n u&apos;is&apos;,\n u&apos;an&apos;,\n u&apos;action&apos;,\n u&apos;that&apos;,\n u&apos;aggregates&apos;,\n u&apos;all&apos;,\n u&apos;the&apos;,\n u&apos;elements&apos;,\n u&apos;of&apos;,\n u&apos;the&apos;,\n u&apos;RDD&apos;,\n u&apos;using&apos;,\n u&apos;some&apos;,\n u&apos;function&apos;,\n u&apos;and&apos;,\n u&apos;returns&apos;,\n u&apos;the&apos;,\n u&apos;final&apos;,\n u&apos;result&apos;,\n u&apos;to&apos;,\n u&apos;the&apos;,\n u&apos;driver&apos;,\n u&apos;program&apos;,\n u&apos;(although&apos;,\n u&apos;there&apos;,\n u&apos;is&apos;,\n u&apos;also&apos;,\n u&apos;a&apos;,\n u&apos;parallel&apos;,\n u&apos;reduceByKey&apos;,\n u&apos;that&apos;,\n u&apos;returns&apos;,\n u&apos;a&apos;,\n u&apos;distributed&apos;,\n u&apos;dataset).&apos;,\n u&apos;&apos;,\n u&apos;All&apos;,\n u&apos;transformations&apos;,\n u&apos;in&apos;,\n u&apos;Spark&apos;,\n u&apos;are&apos;,\n u&apos;lazy,&apos;,\n u&apos;in&apos;,\n u&apos;that&apos;,\n u&apos;they&apos;,\n u&apos;do&apos;,\n u&apos;not&apos;,\n u&apos;compute&apos;,\n u&apos;their&apos;,\n u&apos;results&apos;,\n u&apos;right&apos;,\n u&apos;away.&apos;,\n u&apos;Instead,&apos;,\n u&apos;they&apos;,\n u&apos;just&apos;,\n u&apos;remember&apos;,\n u&apos;the&apos;,\n u&apos;transformations&apos;,\n u&apos;applied&apos;,\n u&apos;to&apos;,\n u&apos;some&apos;,\n u&apos;base&apos;,\n u&apos;dataset&apos;,\n u&apos;(e.g.&apos;,\n u&apos;a&apos;,\n u&apos;file).&apos;,\n u&apos;The&apos;,\n u&apos;transformations&apos;,\n u&apos;are&apos;,\n u&apos;only&apos;,\n u&apos;computed&apos;,\n u&apos;when&apos;,\n u&apos;an&apos;,\n u&apos;action&apos;,\n u&apos;requires&apos;,\n u&apos;a&apos;,\n u&apos;result&apos;,\n u&apos;to&apos;,\n u&apos;be&apos;,\n u&apos;returned&apos;,\n u&apos;to&apos;,\n u&apos;the&apos;,\n u&apos;driver&apos;,\n u&apos;program.&apos;,\n u&apos;This&apos;,\n u&apos;design&apos;,\n u&apos;enables&apos;,\n u&apos;Spark&apos;,\n u&apos;to&apos;,\n u&apos;run&apos;,\n u&apos;more&apos;,\n u&apos;efficiently.&apos;,\n u&apos;For&apos;,\n u&apos;example,&apos;,\n u&apos;we&apos;,\n u&apos;can&apos;,\n u&apos;realize&apos;,\n u&apos;that&apos;,\n u&apos;a&apos;,\n u&apos;dataset&apos;,\n u&apos;created&apos;,\n u&apos;through&apos;,\n u&apos;map&apos;,\n u&apos;will&apos;,\n u&apos;be&apos;,\n u&apos;used&apos;,\n u&apos;in&apos;,\n u&apos;a&apos;,\n u&apos;reduce&apos;,\n u&apos;and&apos;,\n u&apos;return&apos;,\n u&apos;only&apos;,\n u&apos;the&apos;,\n u&apos;result&apos;,\n u&apos;of&apos;,\n u&apos;the&apos;,\n u&apos;reduce&apos;,\n u&apos;to&apos;,\n u&apos;the&apos;,\n u&apos;driver,&apos;,\n u&apos;rather&apos;,\n u&apos;than&apos;,\n u&apos;the&apos;,\n u&apos;larger&apos;,\n u&apos;mapped&apos;,\n u&apos;dataset.&apos;,\n u&apos;&apos;,\n u&apos;By&apos;,\n u&apos;default,&apos;,\n u&apos;each&apos;,\n u&apos;transformed&apos;,\n u&apos;RDD&apos;,\n u&apos;may&apos;,\n u&apos;be&apos;,\n u&apos;recomputed&apos;,\n u&apos;each&apos;,\n u&apos;time&apos;,\n u&apos;you&apos;,\n u&apos;run&apos;,\n u&apos;an&apos;,\n u&apos;action&apos;,\n u&apos;on&apos;,\n u&apos;it.&apos;,\n u&apos;However,&apos;,\n u&apos;you&apos;,\n u&apos;may&apos;,\n u&apos;also&apos;,\n u&apos;persist&apos;,\n u&apos;an&apos;,\n u&apos;RDD&apos;,\n u&apos;in&apos;,\n u&apos;memory&apos;,\n u&apos;using&apos;,\n u&apos;the&apos;,\n u&apos;persist&apos;,\n u&apos;(or&apos;,\n u&apos;cache)&apos;,\n u&apos;method,&apos;,\n u&apos;in&apos;,\n u&apos;which&apos;,\n u&apos;case&apos;,\n u&apos;Spark&apos;,\n u&apos;will&apos;,\n u&apos;keep&apos;,\n u&apos;the&apos;,\n u&apos;elements&apos;,\n u&apos;around&apos;,\n u&apos;on&apos;,\n u&apos;the&apos;,\n u&apos;cluster&apos;,\n u&apos;for&apos;,\n u&apos;much&apos;,\n u&apos;faster&apos;,\n u&apos;access&apos;,\n u&apos;the&apos;,\n u&apos;next&apos;,\n u&apos;time&apos;,\n u&apos;you&apos;,\n u&apos;query&apos;,\n u&apos;it.&apos;,\n u&apos;There&apos;,\n u&apos;is&apos;,\n u&apos;also&apos;,\n u&apos;support&apos;,\n u&apos;for&apos;,\n u&apos;persisting&apos;,\n u&apos;RDDs&apos;,\n u&apos;on&apos;,\n u&apos;disk,&apos;,\n u&apos;or&apos;,\n u&apos;replicated&apos;,\n u&apos;across&apos;,\n u&apos;multiple&apos;,\n u&apos;nodes.&apos;]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["=a1.map(lambda x: (x,1))\nwordKV.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">72</span><span class=\"ansired\">]: </span>\n[(u&apos;RDDs&apos;, 1),\n (u&apos;support&apos;, 1),\n (u&apos;two&apos;, 1),\n (u&apos;types&apos;, 1),\n (u&apos;of&apos;, 1),\n (u&apos;operations:&apos;, 1),\n (u&apos;transformations,&apos;, 1),\n (u&apos;which&apos;, 1),\n (u&apos;create&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;new&apos;, 1),\n (u&apos;dataset&apos;, 1),\n (u&apos;from&apos;, 1),\n (u&apos;an&apos;, 1),\n (u&apos;existing&apos;, 1),\n (u&apos;one,&apos;, 1),\n (u&apos;and&apos;, 1),\n (u&apos;actions,&apos;, 1),\n (u&apos;which&apos;, 1),\n (u&apos;return&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;value&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;driver&apos;, 1),\n (u&apos;program&apos;, 1),\n (u&apos;after&apos;, 1),\n (u&apos;running&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;computation&apos;, 1),\n (u&apos;on&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;dataset.&apos;, 1),\n (u&apos;For&apos;, 1),\n (u&apos;example,&apos;, 1),\n (u&apos;map&apos;, 1),\n (u&apos;is&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;transformation&apos;, 1),\n (u&apos;that&apos;, 1),\n (u&apos;passes&apos;, 1),\n (u&apos;each&apos;, 1),\n (u&apos;dataset&apos;, 1),\n (u&apos;element&apos;, 1),\n (u&apos;through&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;function&apos;, 1),\n (u&apos;and&apos;, 1),\n (u&apos;returns&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;new&apos;, 1),\n (u&apos;RDD&apos;, 1),\n (u&apos;representing&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;results.&apos;, 1),\n (u&apos;On&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;other&apos;, 1),\n (u&apos;hand,&apos;, 1),\n (u&apos;reduce&apos;, 1),\n (u&apos;is&apos;, 1),\n (u&apos;an&apos;, 1),\n (u&apos;action&apos;, 1),\n (u&apos;that&apos;, 1),\n (u&apos;aggregates&apos;, 1),\n (u&apos;all&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;elements&apos;, 1),\n (u&apos;of&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;RDD&apos;, 1),\n (u&apos;using&apos;, 1),\n (u&apos;some&apos;, 1),\n (u&apos;function&apos;, 1),\n (u&apos;and&apos;, 1),\n (u&apos;returns&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;final&apos;, 1),\n (u&apos;result&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;driver&apos;, 1),\n (u&apos;program&apos;, 1),\n (u&apos;(although&apos;, 1),\n (u&apos;there&apos;, 1),\n (u&apos;is&apos;, 1),\n (u&apos;also&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;parallel&apos;, 1),\n (u&apos;reduceByKey&apos;, 1),\n (u&apos;that&apos;, 1),\n (u&apos;returns&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;distributed&apos;, 1),\n (u&apos;dataset).&apos;, 1),\n (u&apos;&apos;, 1),\n (u&apos;All&apos;, 1),\n (u&apos;transformations&apos;, 1),\n (u&apos;in&apos;, 1),\n (u&apos;Spark&apos;, 1),\n (u&apos;are&apos;, 1),\n (u&apos;lazy,&apos;, 1),\n (u&apos;in&apos;, 1),\n (u&apos;that&apos;, 1),\n (u&apos;they&apos;, 1),\n (u&apos;do&apos;, 1),\n (u&apos;not&apos;, 1),\n (u&apos;compute&apos;, 1),\n (u&apos;their&apos;, 1),\n (u&apos;results&apos;, 1),\n (u&apos;right&apos;, 1),\n (u&apos;away.&apos;, 1),\n (u&apos;Instead,&apos;, 1),\n (u&apos;they&apos;, 1),\n (u&apos;just&apos;, 1),\n (u&apos;remember&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;transformations&apos;, 1),\n (u&apos;applied&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;some&apos;, 1),\n (u&apos;base&apos;, 1),\n (u&apos;dataset&apos;, 1),\n (u&apos;(e.g.&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;file).&apos;, 1),\n (u&apos;The&apos;, 1),\n (u&apos;transformations&apos;, 1),\n (u&apos;are&apos;, 1),\n (u&apos;only&apos;, 1),\n (u&apos;computed&apos;, 1),\n (u&apos;when&apos;, 1),\n (u&apos;an&apos;, 1),\n (u&apos;action&apos;, 1),\n (u&apos;requires&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;result&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;be&apos;, 1),\n (u&apos;returned&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;driver&apos;, 1),\n (u&apos;program.&apos;, 1),\n (u&apos;This&apos;, 1),\n (u&apos;design&apos;, 1),\n (u&apos;enables&apos;, 1),\n (u&apos;Spark&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;run&apos;, 1),\n (u&apos;more&apos;, 1),\n (u&apos;efficiently.&apos;, 1),\n (u&apos;For&apos;, 1),\n (u&apos;example,&apos;, 1),\n (u&apos;we&apos;, 1),\n (u&apos;can&apos;, 1),\n (u&apos;realize&apos;, 1),\n (u&apos;that&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;dataset&apos;, 1),\n (u&apos;created&apos;, 1),\n (u&apos;through&apos;, 1),\n (u&apos;map&apos;, 1),\n (u&apos;will&apos;, 1),\n (u&apos;be&apos;, 1),\n (u&apos;used&apos;, 1),\n (u&apos;in&apos;, 1),\n (u&apos;a&apos;, 1),\n (u&apos;reduce&apos;, 1),\n (u&apos;and&apos;, 1),\n (u&apos;return&apos;, 1),\n (u&apos;only&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;result&apos;, 1),\n (u&apos;of&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;reduce&apos;, 1),\n (u&apos;to&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;driver,&apos;, 1),\n (u&apos;rather&apos;, 1),\n (u&apos;than&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;larger&apos;, 1),\n (u&apos;mapped&apos;, 1),\n (u&apos;dataset.&apos;, 1),\n (u&apos;&apos;, 1),\n (u&apos;By&apos;, 1),\n (u&apos;default,&apos;, 1),\n (u&apos;each&apos;, 1),\n (u&apos;transformed&apos;, 1),\n (u&apos;RDD&apos;, 1),\n (u&apos;may&apos;, 1),\n (u&apos;be&apos;, 1),\n (u&apos;recomputed&apos;, 1),\n (u&apos;each&apos;, 1),\n (u&apos;time&apos;, 1),\n (u&apos;you&apos;, 1),\n (u&apos;run&apos;, 1),\n (u&apos;an&apos;, 1),\n (u&apos;action&apos;, 1),\n (u&apos;on&apos;, 1),\n (u&apos;it.&apos;, 1),\n (u&apos;However,&apos;, 1),\n (u&apos;you&apos;, 1),\n (u&apos;may&apos;, 1),\n (u&apos;also&apos;, 1),\n (u&apos;persist&apos;, 1),\n (u&apos;an&apos;, 1),\n (u&apos;RDD&apos;, 1),\n (u&apos;in&apos;, 1),\n (u&apos;memory&apos;, 1),\n (u&apos;using&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;persist&apos;, 1),\n (u&apos;(or&apos;, 1),\n (u&apos;cache)&apos;, 1),\n (u&apos;method,&apos;, 1),\n (u&apos;in&apos;, 1),\n (u&apos;which&apos;, 1),\n (u&apos;case&apos;, 1),\n (u&apos;Spark&apos;, 1),\n (u&apos;will&apos;, 1),\n (u&apos;keep&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;elements&apos;, 1),\n (u&apos;around&apos;, 1),\n (u&apos;on&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;cluster&apos;, 1),\n (u&apos;for&apos;, 1),\n (u&apos;much&apos;, 1),\n (u&apos;faster&apos;, 1),\n (u&apos;access&apos;, 1),\n (u&apos;the&apos;, 1),\n (u&apos;next&apos;, 1),\n (u&apos;time&apos;, 1),\n (u&apos;you&apos;, 1),\n (u&apos;query&apos;, 1),\n (u&apos;it.&apos;, 1),\n (u&apos;There&apos;, 1),\n (u&apos;is&apos;, 1),\n (u&apos;also&apos;, 1),\n (u&apos;support&apos;, 1),\n (u&apos;for&apos;, 1),\n (u&apos;persisting&apos;, 1),\n (u&apos;RDDs&apos;, 1),\n (u&apos;on&apos;, 1),\n (u&apos;disk,&apos;, 1),\n (u&apos;or&apos;, 1),\n (u&apos;replicated&apos;, 1),\n (u&apos;across&apos;, 1),\n (u&apos;multiple&apos;, 1),\n (u&apos;nodes.&apos;, 1)]\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["wordKVg=wordKV.groupByKey()\n#wordKVg.map(lambda (x,y): (x,sum(y)) ).collect()\nwordKVg.mapValues(lambda y: sum(y) ).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">89</span><span class=\"ansired\">]: </span>\n[(u&apos;&apos;, 2),\n (u&apos;and&apos;, 4),\n (u&apos;all&apos;, 1),\n (u&apos;just&apos;, 1),\n (u&apos;hand,&apos;, 1),\n (u&apos;when&apos;, 1),\n (u&apos;is&apos;, 4),\n (u&apos;one,&apos;, 1),\n (u&apos;transformations,&apos;, 1),\n (u&apos;case&apos;, 1),\n (u&apos;through&apos;, 2),\n (u&apos;computation&apos;, 1),\n (u&apos;it.&apos;, 2),\n (u&apos;run&apos;, 2),\n (u&apos;method,&apos;, 1),\n (u&apos;recomputed&apos;, 1),\n (u&apos;from&apos;, 1),\n (u&apos;For&apos;, 2),\n (u&apos;for&apos;, 2),\n (u&apos;rather&apos;, 1),\n (u&apos;create&apos;, 1),\n (u&apos;distributed&apos;, 1),\n (u&apos;returns&apos;, 3),\n (u&apos;access&apos;, 1),\n (u&apos;may&apos;, 2),\n (u&apos;only&apos;, 2),\n (u&apos;transformed&apos;, 1),\n (u&apos;types&apos;, 1),\n (u&apos;which&apos;, 3),\n (u&apos;results.&apos;, 1),\n (u&apos;disk,&apos;, 1),\n (u&apos;program.&apos;, 1),\n (u&apos;aggregates&apos;, 1),\n (u&apos;dataset.&apos;, 2),\n (u&apos;function&apos;, 2),\n (u&apos;a&apos;, 12),\n (u&apos;we&apos;, 1),\n (u&apos;However,&apos;, 1),\n (u&apos;return&apos;, 2),\n (u&apos;multiple&apos;, 1),\n (u&apos;This&apos;, 1),\n (u&apos;some&apos;, 2),\n (u&apos;example,&apos;, 2),\n (u&apos;driver&apos;, 3),\n (u&apos;persisting&apos;, 1),\n (u&apos;reduce&apos;, 3),\n (u&apos;running&apos;, 1),\n (u&apos;(or&apos;, 1),\n (u&apos;they&apos;, 2),\n (u&apos;not&apos;, 1),\n (u&apos;The&apos;, 1),\n (u&apos;representing&apos;, 1),\n (u&apos;Spark&apos;, 3),\n (u&apos;efficiently.&apos;, 1),\n (u&apos;applied&apos;, 1),\n (u&apos;All&apos;, 1),\n (u&apos;compute&apos;, 1),\n (u&apos;value&apos;, 1),\n (u&apos;will&apos;, 2),\n (u&apos;dataset).&apos;, 1),\n (u&apos;you&apos;, 3),\n (u&apos;action&apos;, 3),\n (u&apos;design&apos;, 1),\n (u&apos;the&apos;, 18),\n (u&apos;requires&apos;, 1),\n (u&apos;support&apos;, 2),\n (u&apos;Instead,&apos;, 1),\n (u&apos;RDDs&apos;, 2),\n (u&apos;right&apos;, 1),\n (u&apos;computed&apos;, 1),\n (u&apos;be&apos;, 3),\n (u&apos;do&apos;, 1),\n (u&apos;By&apos;, 1),\n (u&apos;keep&apos;, 1),\n (u&apos;There&apos;, 1),\n (u&apos;results&apos;, 1),\n (u&apos;existing&apos;, 1),\n (u&apos;time&apos;, 2),\n (u&apos;away.&apos;, 1),\n (u&apos;elements&apos;, 2),\n (u&apos;result&apos;, 3),\n (u&apos;faster&apos;, 1),\n (u&apos;in&apos;, 5),\n (u&apos;query&apos;, 1),\n (u&apos;element&apos;, 1),\n (u&apos;next&apos;, 1),\n (u&apos;their&apos;, 1),\n (u&apos;around&apos;, 1),\n (u&apos;are&apos;, 2),\n (u&apos;passes&apos;, 1),\n (u&apos;or&apos;, 1),\n (u&apos;transformations&apos;, 3),\n (u&apos;reduceByKey&apos;, 1),\n (u&apos;default,&apos;, 1),\n (u&apos;there&apos;, 1),\n (u&apos;two&apos;, 1),\n (u&apos;operations:&apos;, 1),\n (u&apos;to&apos;, 7),\n (u&apos;program&apos;, 2),\n (u&apos;file).&apos;, 1),\n (u&apos;persist&apos;, 2),\n (u&apos;replicated&apos;, 1),\n (u&apos;new&apos;, 2),\n (u&apos;driver,&apos;, 1),\n (u&apos;transformation&apos;, 1),\n (u&apos;across&apos;, 1),\n (u&apos;more&apos;, 1),\n (u&apos;dataset&apos;, 4),\n (u&apos;On&apos;, 1),\n (u&apos;used&apos;, 1),\n (u&apos;an&apos;, 5),\n (u&apos;returned&apos;, 1),\n (u&apos;than&apos;, 1),\n (u&apos;that&apos;, 5),\n (u&apos;each&apos;, 3),\n (u&apos;much&apos;, 1),\n (u&apos;RDD&apos;, 4),\n (u&apos;base&apos;, 1),\n (u&apos;nodes.&apos;, 1),\n (u&apos;(although&apos;, 1),\n (u&apos;using&apos;, 2),\n (u&apos;(e.g.&apos;, 1),\n (u&apos;realize&apos;, 1),\n (u&apos;after&apos;, 1),\n (u&apos;cache)&apos;, 1),\n (u&apos;on&apos;, 4),\n (u&apos;lazy,&apos;, 1),\n (u&apos;memory&apos;, 1),\n (u&apos;remember&apos;, 1),\n (u&apos;created&apos;, 1),\n (u&apos;of&apos;, 3),\n (u&apos;also&apos;, 3),\n (u&apos;larger&apos;, 1),\n (u&apos;final&apos;, 1),\n (u&apos;cluster&apos;, 1),\n (u&apos;map&apos;, 2),\n (u&apos;can&apos;, 1),\n (u&apos;mapped&apos;, 1),\n (u&apos;parallel&apos;, 1),\n (u&apos;enables&apos;, 1),\n (u&apos;other&apos;, 1),\n (u&apos;actions,&apos;, 1)]\n</div>"]}}],"execution_count":15},{"cell_type":"code","source":["wordKV.reduceByKey(lambda a,b:a+b).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">91</span><span class=\"ansired\">]: </span>\n[(u&apos;&apos;, 2),\n (u&apos;and&apos;, 4),\n (u&apos;all&apos;, 1),\n (u&apos;just&apos;, 1),\n (u&apos;hand,&apos;, 1),\n (u&apos;when&apos;, 1),\n (u&apos;is&apos;, 4),\n (u&apos;one,&apos;, 1),\n (u&apos;transformations,&apos;, 1),\n (u&apos;case&apos;, 1),\n (u&apos;through&apos;, 2),\n (u&apos;computation&apos;, 1),\n (u&apos;it.&apos;, 2),\n (u&apos;run&apos;, 2),\n (u&apos;method,&apos;, 1),\n (u&apos;recomputed&apos;, 1),\n (u&apos;from&apos;, 1),\n (u&apos;For&apos;, 2),\n (u&apos;for&apos;, 2),\n (u&apos;rather&apos;, 1),\n (u&apos;create&apos;, 1),\n (u&apos;distributed&apos;, 1),\n (u&apos;returns&apos;, 3),\n (u&apos;access&apos;, 1),\n (u&apos;may&apos;, 2),\n (u&apos;only&apos;, 2),\n (u&apos;transformed&apos;, 1),\n (u&apos;types&apos;, 1),\n (u&apos;which&apos;, 3),\n (u&apos;results.&apos;, 1),\n (u&apos;disk,&apos;, 1),\n (u&apos;program.&apos;, 1),\n (u&apos;aggregates&apos;, 1),\n (u&apos;dataset.&apos;, 2),\n (u&apos;function&apos;, 2),\n (u&apos;a&apos;, 12),\n (u&apos;we&apos;, 1),\n (u&apos;However,&apos;, 1),\n (u&apos;return&apos;, 2),\n (u&apos;multiple&apos;, 1),\n (u&apos;This&apos;, 1),\n (u&apos;some&apos;, 2),\n (u&apos;example,&apos;, 2),\n (u&apos;driver&apos;, 3),\n (u&apos;persisting&apos;, 1),\n (u&apos;reduce&apos;, 3),\n (u&apos;running&apos;, 1),\n (u&apos;(or&apos;, 1),\n (u&apos;they&apos;, 2),\n (u&apos;not&apos;, 1),\n (u&apos;The&apos;, 1),\n (u&apos;representing&apos;, 1),\n (u&apos;Spark&apos;, 3),\n (u&apos;efficiently.&apos;, 1),\n (u&apos;applied&apos;, 1),\n (u&apos;All&apos;, 1),\n (u&apos;compute&apos;, 1),\n (u&apos;value&apos;, 1),\n (u&apos;will&apos;, 2),\n (u&apos;dataset).&apos;, 1),\n (u&apos;you&apos;, 3),\n (u&apos;action&apos;, 3),\n (u&apos;design&apos;, 1),\n (u&apos;the&apos;, 18),\n (u&apos;requires&apos;, 1),\n (u&apos;support&apos;, 2),\n (u&apos;Instead,&apos;, 1),\n (u&apos;RDDs&apos;, 2),\n (u&apos;right&apos;, 1),\n (u&apos;computed&apos;, 1),\n (u&apos;be&apos;, 3),\n (u&apos;do&apos;, 1),\n (u&apos;By&apos;, 1),\n (u&apos;keep&apos;, 1),\n (u&apos;There&apos;, 1),\n (u&apos;results&apos;, 1),\n (u&apos;existing&apos;, 1),\n (u&apos;time&apos;, 2),\n (u&apos;away.&apos;, 1),\n (u&apos;elements&apos;, 2),\n (u&apos;result&apos;, 3),\n (u&apos;faster&apos;, 1),\n (u&apos;in&apos;, 5),\n (u&apos;query&apos;, 1),\n (u&apos;element&apos;, 1),\n (u&apos;next&apos;, 1),\n (u&apos;their&apos;, 1),\n (u&apos;around&apos;, 1),\n (u&apos;are&apos;, 2),\n (u&apos;passes&apos;, 1),\n (u&apos;or&apos;, 1),\n (u&apos;transformations&apos;, 3),\n (u&apos;reduceByKey&apos;, 1),\n (u&apos;default,&apos;, 1),\n (u&apos;there&apos;, 1),\n (u&apos;two&apos;, 1),\n (u&apos;operations:&apos;, 1),\n (u&apos;to&apos;, 7),\n (u&apos;program&apos;, 2),\n (u&apos;file).&apos;, 1),\n (u&apos;persist&apos;, 2),\n (u&apos;replicated&apos;, 1),\n (u&apos;new&apos;, 2),\n (u&apos;driver,&apos;, 1),\n (u&apos;transformation&apos;, 1),\n (u&apos;across&apos;, 1),\n (u&apos;more&apos;, 1),\n (u&apos;dataset&apos;, 4),\n (u&apos;On&apos;, 1),\n (u&apos;used&apos;, 1),\n (u&apos;an&apos;, 5),\n (u&apos;returned&apos;, 1),\n (u&apos;than&apos;, 1),\n (u&apos;that&apos;, 5),\n (u&apos;each&apos;, 3),\n (u&apos;much&apos;, 1),\n (u&apos;RDD&apos;, 4),\n (u&apos;base&apos;, 1),\n (u&apos;nodes.&apos;, 1),\n (u&apos;(although&apos;, 1),\n (u&apos;using&apos;, 2),\n (u&apos;(e.g.&apos;, 1),\n (u&apos;realize&apos;, 1),\n (u&apos;after&apos;, 1),\n (u&apos;cache)&apos;, 1),\n (u&apos;on&apos;, 4),\n (u&apos;lazy,&apos;, 1),\n (u&apos;memory&apos;, 1),\n (u&apos;remember&apos;, 1),\n (u&apos;created&apos;, 1),\n (u&apos;of&apos;, 3),\n (u&apos;also&apos;, 3),\n (u&apos;larger&apos;, 1),\n (u&apos;final&apos;, 1),\n (u&apos;cluster&apos;, 1),\n (u&apos;map&apos;, 2),\n (u&apos;can&apos;, 1),\n (u&apos;mapped&apos;, 1),\n (u&apos;parallel&apos;, 1),\n (u&apos;enables&apos;, 1),\n (u&apos;other&apos;, 1),\n (u&apos;actions,&apos;, 1)]\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["wordKV.reduceByKey(lambda a,b:a+b,1).saveAsTextFile(\"/FileStore/tables/abc\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"code","source":["wordKV.reduceByKey(lambda a,b:a+b,2).saveAsTextFile(\"/FileStore/tables/abc1\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["pat=wordKV.reduceByKey(lambda a,b:a+b,2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["wordKV.reduceByKey(lambda a,b:a+b,2).repartition(6).getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">99</span><span class=\"ansired\">]: </span>6\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["wordKV.reduceByKey(lambda a,b:a+b)."],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["a=sc.parallelize([0,2,1,4,2,1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["a.mapPartitions(lambda x:x+1).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-496538373508776&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>a<span class=\"ansiyellow\">.</span>mapPartitions<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> x<span class=\"ansiyellow\">:</span>x<span class=\"ansiyellow\">+</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">collect</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    814</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    815</span>         <span class=\"ansigreen\">with</span> SCCallSiteSync<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>context<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">as</span> css<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 816</span><span class=\"ansiyellow\">             </span>sock_info <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>ctx<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonRDD<span class=\"ansiyellow\">.</span>collectAndServe<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jrdd<span class=\"ansiyellow\">.</span>rdd<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    817</span>         <span class=\"ansigreen\">return</span> list<span class=\"ansiyellow\">(</span>_load_from_socket<span class=\"ansiyellow\">(</span>sock_info<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>_jrdd_deserializer<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    818</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 80.0 failed 1 times, most recent failure: Lost task 4.0 in stage 80.0 (TID 293, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 372, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 367, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 352, in func\n    return f(iterator)\n  File &quot;&lt;command-496538373508776&gt;&quot;, line 1, in &lt;lambda&gt;\nTypeError: unsupported operand type(s) for +: &apos;itertools.chain&apos; and &apos;int&apos;\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:469)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:605)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:423)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:958)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:958)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2221)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2221)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:124)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:459)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1401)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2025)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2013)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2012)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2012)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1057)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1057)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2248)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2196)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2184)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:854)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2181)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2221)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2246)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:958)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:376)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:957)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:200)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.GeneratedMethodAccessor418.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 372, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 367, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 352, in func\n    return f(iterator)\n  File &quot;&lt;command-496538373508776&gt;&quot;, line 1, in &lt;lambda&gt;\nTypeError: unsupported operand type(s) for +: &apos;itertools.chain&apos; and &apos;int&apos;\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:469)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:605)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:588)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:423)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:958)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:958)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2221)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2221)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:124)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:459)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1401)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["empKV.leftOuterJoin(depKV).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">105</span><span class=\"ansired\">]: </span>\n[(29, ([u&apos;Michael&apos;, u&apos; 29&apos;], [u&apos;29&apos;, u&apos;Dep1&apos;])),\n (30, ([u&apos;Andy&apos;, u&apos; 30&apos;], [u&apos;30&apos;, u&apos;Dep2&apos;])),\n (19, ([u&apos;Justin&apos;, u&apos; 19&apos;], [u&apos;19&apos;, u&apos;Dep3&apos;]))]\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["a=sc.parallelize([1,2,3,4])\nbValue=sc.broadcast([1,2,3])\na.map(lambda x: x+bValue.value[1]).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">111</span><span class=\"ansired\">]: </span>[3, 4, 5, 6]\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["acc=sc.accumulator(0)\n\ndef accumulate1(row):\n    if row[0][0]=='M':\n        acc.add(1)\n    \n\nb1.map(lambda x: x.split(\",\")).foreach(accumulate1)\n\nprint(acc.value)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["a=[u'Michael', u' 29']\na[0][0]=='M'"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">117</span><span class=\"ansired\">]: </span>True\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["b1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">129</span><span class=\"ansired\">]: </span>[u&apos;Michael, 29&apos;, u&apos;Andy, 30&apos;, u&apos;Justin, 19&apos;]\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["b1=sc.textFile(\"/FileStore/tables/people.txt\")\nm=b1.map(lambda x: x.split(\",\"))\n\nfrom pyspark import StorageLevel\nm.persist(StorageLevel.MEMORY_AND_DISK_2)\n\nk=m.filter(lambda (x,y): int(y)>20)\n\ns=m.filter(lambda (x,y): x[0]=='M')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["s.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">146</span><span class=\"ansired\">]: </span>[[u&apos;Michael&apos;, u&apos; 29&apos;]]\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["k.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">147</span><span class=\"ansired\">]: </span>[[u&apos;Michael&apos;, u&apos; 29&apos;], [u&apos;Andy&apos;, u&apos; 30&apos;]]\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["df=spark.read.json(\"/FileStore/tables/people.json\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- age: long (nullable = true)\n-- name: string (nullable = true)\n\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["df.show(1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-------+\n age|   name|\n+----+-------+\nnull|Michael|\n+----+-------+\nonly showing top 1 row\n\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["df.select(df[\"name\"], df[\"age\"] + 1).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---------+\n   name|(age + 1)|\n+-------+---------+\nMichael|     null|\n   Andy|       31|\n Justin|       20|\n+-------+---------+\n\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["df.filter(df[\"age\"] > 21).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----+\nage|name|\n+---+----+\n 30|Andy|\n+---+----+\n\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["df.filter(df[\"age\"] > 21).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----+\nage|name|\n+---+----+\n 30|Andy|\n+---+----+\n\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["df.createOrReplaceTempView(\"people\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"code","source":["sqlDF = spark.sql(\"SELECT * FROM people\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":39},{"cell_type":"code","source":["sqlDF.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-------+\n age|   name|\n+----+-------+\nnull|Michael|\n  30|   Andy|\n  19| Justin|\n+----+-------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["df.schema"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">14</span><span class=\"ansired\">]: </span>StructType(List(StructField(age,LongType,true),StructField(name,StringType,true)))\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["b1=sc.textFile(\"/FileStore/tables/people.txt\")\n\nb1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>[u&apos;Michael, 29&apos;, u&apos;Andy, 30&apos;, u&apos;Justin, 19&apos;]\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["b1=sc.textFile(\"/FileStore/tables/people.txt\")\nparts = b1.map(lambda x:x.split(\",\"))\npeople1 = parts.map(lambda p: (p[0], p[1].strip()))\npeople1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">48</span><span class=\"ansired\">]: </span>[(u&apos;Michael&apos;, u&apos;29&apos;), (u&apos;Andy&apos;, u&apos;30&apos;), (u&apos;Justin&apos;, u&apos;19&apos;)]\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["schemaString = \"name age\"\nfrom pyspark.sql.types import *\n\nfields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\nschema = StructType(fields)\nschema\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">23</span><span class=\"ansired\">]: </span>StructType(List(StructField(name,StringType,true),StructField(age,StringType,true)))\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["df1=spark.createDataFrame(people1,schema)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---+\n   name|age|\n+-------+---+\nMichael| 29|\n   Andy| 30|\n Justin| 19|\n+-------+---+\n\n</div>"]}}],"execution_count":46},{"cell_type":"code","source":["def squared1(s):\n  return s * s\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":47},{"cell_type":"code","source":["ss=spark.udf.register(\"squaredWithPython\", squared1)\n\n#df1.select(\"age\", ss(df(\"age\").alias(\"id_squared\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"code","source":["\nk=df1.select( ss(\"age\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":49},{"cell_type":"code","source":["k.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1887795129595931&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>k<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">show</span><span class=\"ansiblue\">(self, n, truncate, vertical)</span>\n<span class=\"ansigreen\">    378</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    379</span>         <span class=\"ansigreen\">if</span> isinstance<span class=\"ansiyellow\">(</span>truncate<span class=\"ansiyellow\">,</span> bool<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">and</span> truncate<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 380</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>showString<span class=\"ansiyellow\">(</span>n<span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">20</span><span class=\"ansiyellow\">,</span> vertical<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    381</span>         <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    382</span>             <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>showString<span class=\"ansiyellow\">(</span>n<span class=\"ansiyellow\">,</span> int<span class=\"ansiyellow\">(</span>truncate<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> vertical<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o1599.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 35.0 failed 1 times, most recent failure: Lost task 0.0 in stage 35.0 (TID 66, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 372, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 367, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 243, in &lt;lambda&gt;\n    func = lambda _, it: map(mapper, it)\n  File &quot;&lt;string&gt;&quot;, line 1, in &lt;lambda&gt;\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 80, in &lt;lambda&gt;\n    return lambda *a: f(*a)\n  File &quot;/databricks/spark/python/pyspark/util.py&quot;, line 99, in wrapper\n    return f(*args, **kwargs)\n  File &quot;&lt;command-1887795129595928&gt;&quot;, line 2, in squared1\nTypeError: can&apos;t multiply sequence by non-int of type &apos;unicode&apos;\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:469)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:423)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:51)\n\tat org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:148)\n\tat org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:147)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:124)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:459)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1401)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2025)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2013)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2012)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2012)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1057)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1057)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2248)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2196)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2184)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:854)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2181)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:259)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:269)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:69)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:75)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:497)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollectResult(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectResult(Dataset.scala:2822)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3446)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2551)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2551)\n\tat org.apache.spark.sql.Dataset$$anonfun$55.apply(Dataset.scala:3430)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withCustomExecutionEnv$1.apply(SQLExecution.scala:89)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:196)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:84)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:126)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3429)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2551)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:260)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:297)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 372, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 367, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 243, in &lt;lambda&gt;\n    func = lambda _, it: map(mapper, it)\n  File &quot;&lt;string&gt;&quot;, line 1, in &lt;lambda&gt;\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 80, in &lt;lambda&gt;\n    return lambda *a: f(*a)\n  File &quot;/databricks/spark/python/pyspark/util.py&quot;, line 99, in wrapper\n    return f(*args, **kwargs)\n  File &quot;&lt;command-1887795129595928&gt;&quot;, line 2, in squared1\nTypeError: can&apos;t multiply sequence by non-int of type &apos;unicode&apos;\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:469)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:423)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:51)\n\tat org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:148)\n\tat org.apache.spark.sql.execution.collect.Collector$$anonfun$2.apply(Collector.scala:147)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:124)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$11.apply(Executor.scala:459)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1401)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:465)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>"]}}],"execution_count":50},{"cell_type":"code","source":["df1.write.parquet(\"people_parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":51},{"cell_type":"code","source":["df2=spark.read.parquet(\"people_parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["df2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---+\n   name|age|\n+-------+---+\n Justin| 19|\nMichael| 29|\n   Andy| 30|\n+-------+---+\n\n</div>"]}}],"execution_count":53},{"cell_type":"code","source":["df_pd = spark.(data={'integers': [1, 2, 3],'floats': [-1.0, 0.5, 2.7],'integer_arrays': [[1, 2], [3, 4, 5], [6, 7, 8, 9]]}\n)\ndf = spark.createDataFrame(df_pd)\ndf.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1887795129595935&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> df_pd = spark.DataFrame(data={&apos;integers&apos;: [1, 2, 3],&apos;floats&apos;: [-1.0, 0.5, 2.7],&apos;integer_arrays&apos;: [[1, 2], [3, 4, 5], [6, 7, 8, 9]]}\n</span><span class=\"ansigreen\">      2</span> )\n<span class=\"ansigreen\">      3</span> df <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span>df_pd<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> df<span class=\"ansiyellow\">.</span>printSchema<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;SparkSession&apos; object has no attribute &apos;DataFrame&apos;</div>"]}}],"execution_count":54},{"cell_type":"code","source":["df.createGlobalTempView(\"people\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1887795129595936&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>createGlobalTempView<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;people&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> spark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;SELECT * FROM global_temp.people&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">createGlobalTempView</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">    200</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    201</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 202</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>createGlobalTempView<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    203</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    204</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">2.2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     69</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 71</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     72</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.parser.ParseException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     73</span>                 <span class=\"ansigreen\">raise</span> ParseException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: u&quot;Temporary view &apos;people&apos; already exists;&quot;</div>"]}}],"execution_count":55},{"cell_type":"code","source":["spark.sql(\"SELECT * FROM global_temp.people\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-------+\n age|   name|\n+----+-------+\nnull|Michael|\n  30|   Andy|\n  19| Justin|\n+----+-------+\n\n</div>"]}}],"execution_count":56},{"cell_type":"code","source":["spark.newSession().sql(\"SELECT * FROM global_temp.people\").show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-------+\n age|   name|\n+----+-------+\nnull|Michael|\n  30|   Andy|\n  19| Justin|\n+----+-------+\n\n</div>"]}}],"execution_count":57},{"cell_type":"code","source":["spark.range(1, 20).createOrReplaceTempView(\"test\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["\ndf12=spark.range(1, 20)\ndf12.createOrReplaceTempView(\"test\")\ndef squared(s):\n  return s * s\nk=spark.udf.register(\"squaredWithPython\", squared)\ndisplay(df12.select(\"id\", k(\"id\").alias(\"id_squared\")))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":59},{"cell_type":"code","source":["spark.sql(\"select id, squaredWithPython(id) as id_squared from test\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+----------+\n id|id_squared|\n+---+----------+\n  1|         1|\n  2|         4|\n  3|         9|\n  4|        16|\n  5|        25|\n  6|        36|\n  7|        49|\n  8|        64|\n  9|        81|\n 10|       100|\n 11|       121|\n 12|       144|\n 13|       169|\n 14|       196|\n 15|       225|\n 16|       256|\n 17|       289|\n 18|       324|\n 19|       361|\n+---+----------+\n\n</div>"]}}],"execution_count":60},{"cell_type":"code","source":["df12=spark.range(1, 20)\ndisplay(df12.select(\"id\", k(\"id\").alias(\"id_squared\")))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>id_squared</th></tr></thead><tbody><tr><td>1</td><td>1</td></tr><tr><td>2</td><td>4</td></tr><tr><td>3</td><td>9</td></tr><tr><td>4</td><td>16</td></tr><tr><td>5</td><td>25</td></tr><tr><td>6</td><td>36</td></tr><tr><td>7</td><td>49</td></tr><tr><td>8</td><td>64</td></tr><tr><td>9</td><td>81</td></tr><tr><td>10</td><td>100</td></tr><tr><td>11</td><td>121</td></tr><tr><td>12</td><td>144</td></tr><tr><td>13</td><td>169</td></tr><tr><td>14</td><td>196</td></tr><tr><td>15</td><td>225</td></tr><tr><td>16</td><td>256</td></tr><tr><td>17</td><td>289</td></tr><tr><td>18</td><td>324</td></tr><tr><td>19</td><td>361</td></tr></tbody></table></div>"]}}],"execution_count":61},{"cell_type":"code","source":["df12=spark.range(1, 20)\ndf12.createOrReplaceTempView(\"test\")\ndef squared(s):\n  return s * s\nk=spark.udf.register(\"squaredWithPython\", <GREEN>)\ndisplay(df12.select(\"id\", <RED>(\"id\").alias(\"id_squared\")))\nspark.sql(\"select id, <BLUE>(id) as id_squared from test\").show()\n\nGREEN -squared\nBLUE -squaredWithPython\nRED - k\n"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["df = spark.read.load(\"/FileStore/tables/people.csv\",\n                     format=\"csv\", sep=\":\", inferSchema=\"true\", header=\"true\")\n\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"code","source":["df.write.format(\"orc\").save(\"people_orc\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":64},{"cell_type":"code","source":["df=spark.sql(\"select * from <schema>.<tablename>\")"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\nTableA = spark.createDataFrame(valuesA,['name','id'])\n \nvaluesB = [('Rutabaga',1),('Pirate',2),('Ninja',3),('Darth Vader',4)]\nTableB = spark.createDataFrame(valuesB,['name','id'])\n \nTableA.show()\nTableB.show()\n\nta = TableA.alias('ta')\ntb = TableB.alias('tb')valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\nTableA = spark.createDataFrame(valuesA,['name','id'])\n \nvaluesB = [('Rutabaga',1),('Pirate',2),('Ninja',3),('Darth Vader',4)]\nTableB = spark.createDataFrame(valuesB,['name','id'])\n \nTableA.show()\nTableB.show()\n\nta = TableA.alias('ta')\ntb = TableB.alias('tb')\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+\n     name| id|\n+---------+---+\n   Pirate|  1|\n   Monkey|  2|\n    Ninja|  3|\nSpaghetti|  4|\n+---------+---+\n\n+-----------+---+\n       name| id|\n+-----------+---+\n   Rutabaga|  1|\n     Pirate|  2|\n      Ninja|  3|\nDarth Vader|  4|\n+-----------+---+\n\n</div>"]}}],"execution_count":66},{"cell_type":"code","source":["valuesA = [('Pirate',1),('Monkey',2),('Ninja',3),('Spaghetti',4)]\nTableA = spark.createDataFrame(valuesA,['name','id'])\n \nvaluesB = [('Rutabaga',1),('Pirate',2),('Ninja',3),('Darth Vader',4)]\nTableB = spark.createDataFrame(valuesB,['name','id'])\n \nTableA.show()\nTableB.show()\n\nta = TableA.alias('ta')\ntb = TableB.alias('tb')\n\nfrom pyspark.sql.functions import broadcast\n\nleft_join = ta.join(broadcast(tb), ta.name == tb.name,how='left') # Could also use 'left_outer'\nleft_join.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---+------+----+\n     name| id|  name|  id|\n+---------+---+------+----+\nSpaghetti|  4|  null|null|\n    Ninja|  3| Ninja|   3|\n   Pirate|  1|Pirate|   2|\n   Monkey|  2|  null|null|\n+---------+---+------+----+\n\n</div>"]}}],"execution_count":67},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"code","source":["from pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\n# Create a local StreamingContext with two working thread and batch interval of 1 second\n\nssc = StreamingContext(spark.sparkContext, 1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":69},{"cell_type":"code","source":["df = spark.read.load(\"/FileStore/tables/people.csv\",\n                     format=\"csv\", sep=\":\", inferSchema=\"true\", header=\"true\")"],"metadata":{},"outputs":[],"execution_count":70}],"metadata":{"name":"Train","notebookId":496538373508738},"nbformat":4,"nbformat_minor":0}
